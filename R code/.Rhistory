m3b <- lm(overall ~ rides + games + wait + clean + weekend + num.child.factor,
data=sat.df)
sat.df$num.child.factor <- factor(sat.df$num.child)
m3b <- lm(overall ~ rides + games + wait + clean + weekend + num.child.factor,
data=sat.df)
summary(m3b)
m3a <- lm(overall ~ rides + games + wait + clean + weekend + num.child,
data = sat.df)
summary(m3a)
# Adding num.child as a factor
sat.df$num.child.factor <- factor(sat.df$num.child)
m3b <- lm(overall ~ rides + games + wait + clean + weekend + num.child.factor,
data=sat.df)
summary(m3b)
contrasts(num.child.factor)
contrasts(sat.df$num.child.factor)
rm(m3a)
rm(m3b)
m3 <- lm(overall ~ rides + games + wait + clean + weekend + num.child,
data = sat.df)
summary(m3)
# Adding num.child as a factor
sat.df$num.child.factor <- factor(sat.df$num.child)
m4 <- lm(overall ~ rides + games + wait + clean + weekend + num.child.factor,
data=sat.df)
summary(m4)
rm(m4a)
rm(m4)
contrasts(sat.df$num.child.factor)
contrasts(sat.df$num.child.factor) <- contr.sum(levels(sat.df$num.child))
contrasts(sat.df$num.child.factor) <- contr.sum(levels(sat.df$num.child)-1)
contrasts(sat.df$num.child.factor) <- contr.sum(5)
levels(sat.df$num.child.factor)
contrasts(sat.df$num.child.factor) <- contr.sum(6)
contrasts(sat.df$num.child.factor)
contrasts(sat.df$num.child.factor) <- contr.sum(6)
contrasts(sat.df$num.child.factor)
m4b <- lm(overall ~ rides + games + wait + clean + weekend + num.child.factor,
data=sat.df)
summary(m4b)
?contrasts
contrasts(sat.df$weekend) <- contr.sum  # changes to sum contrasts (aka effect coding)
contrasts(sat.df$weekend)
m2b <- lm(overall ~ rides + games + wait + clean + weekend,
data = sat.df)
summary(m2b) # coeficients now match JMP
m3 <- lm(overall ~ rides + games + wait + clean + weekend + num.child,
data = sat.df)
summary(m3)
# Adding num.child as a factor
sat.df$num.child.factor <- factor(sat.df$num.child)
m4a <- lm(overall ~ rides + games + wait + clean + weekend + num.child.factor,
m3 <- lm(overall ~ rides + games + wait + clean + weekend + num.child,
data = sat.df)
summary(m3)
m3 <- lm(overall ~ rides + games + wait + clean + weekend + num.child,
data = sat.df)
summary(m3)
# Adding num.child as a factor
sat.df$num.child.factor <- factor(sat.df$num.child)
m4a <- lm(overall ~ rides + games + wait + clean + weekend + num.child.factor,
data=sat.df)
summary(m4a)
contrasts(sat.df$num.child.factor) # Default coding for a factor with 5 levels (R default)
sat.df$num.child.factor <- relevel(sat.df$num.child.factor, ref="num.child.factor0")
levels(sat.df$num.child.factor)
sat.df$num.child.factor <- relevel(sat.df$num.child.factor, ref="0")
# Change to sum contrast (which will match JMP output)
contrasts(sat.df$num.child.factor) <- contr.sum
contrasts(sat.df$num.child.factor)
contrasts(sat.df$num.child.factor) <- contr.sum
# Make zero children the reference level
sat.df$num.child.factor <- relevel(sat.df$num.child.factor, ref="0")
contrasts(sat.df$num.child.factor)
contrasts(sat.df$num.child.factor) <- contr.sum
contrasts(sat.df$num.child.factor)
m4b <- lm(overall ~ rides + games + wait + clean + weekend + num.child.factor,
data=sat.df)
summary(m4b)
sat.df$has.child <- factor(sat.std$num.child > 0)
m5 <- lm(overall ~ rides + games + wait + clean + logdist + has.child,
data=sat.std)
summary(m5)
# Switch to a binary variable for "has children"
sat.df$has.child <- factor(sat.std$num.child > 0)
sat.df$has.child <- factor(sat.df$num.child > 0)
sat.df$has.child <- factor(sat.df$num.child > 0)
m5 <- lm(overall ~ rides + games + wait + clean + logdist + has.child,
data=sat.df)
sat.df$has.child <- factor(sat.df$num.child > 0)
m5 <- lm(overall ~ rides + games + wait + clean + has.child,
data=sat.df)
summary(m5)
# ======= Interactions
m6 <- lm(overall ~ rides + games + wait + clean + weekend + has.child +
rides:has.child + games:has.child + wait:has.child + clean:has.child +
rides:weekend + games:weekend + wait:weekend + clean:weekend,
data=sat.std)
summary(m6)
m6 <- lm(overall ~ rides + games + wait + clean + weekend + has.child +
rides:has.child + games:has.child + wait:has.child + clean:has.child +
rides:weekend + games:weekend + wait:weekend + clean:weekend,
data=sat.df)
summary(m6)
contrasts(weekend)
contrasts(sat.df$weekend)
contrasts(sat.df$had.child)
contrasts(sat.df$has.child)
contrasts(sat.df$has.child) <- contr.sum
m5 <- lm(overall ~ rides + games + wait + clean + has.child,
data=sat.df)
summary(m5)
rm(list=ls())
sat.df <- read.csv("S10_Satisfaction_Drivers_ChapmanFeitCh7.csv")
sat.df <- read.csv("http://goo.gl/HKnl74") # alternatively read from Chapman and Feit website
summary(sat.df)
# Graph
barplot(colMeans(sat.df[4:8]), ylab="Average Satisfaction")
histogram(sat.df$overall, xlab="Overall Satisfaction with Park",
ylab="Percent of Visitors", col="gray")
histogram(sat.df$rides, xlab="Satisfaction with Rides",
ylab="Percent of Visitors", col="gray")
plot(sat.df$rides, sat.df$overall, ylab="Overall Satisfaction with Park",
xlab="Satisfaction with Rides")
# ======= Linear model with continuous predictors
m1 <- lm(overall ~ rides + games + wait + clean, data=sat.df)
summary(m1)
# confidence intervals for parameters
confint(m1)
# Prediction: what overall rating would we predict for someone who gives a 100
# rating for all four features.
predict(m1, data.frame(rides=c(100), games=c(100), wait=c(100), clean=c(100)))
# Prediction by hand: Note we are literally plugging in values for the variables
coef(m1)["(Intercept)"] + coef(m1)["rides"]*100 + coef(m1)["games"]*100 +
coef(m1)["wait"]*100 + coef(m1)["clean"]*100
coef(m1)%*%c(1,100, 100, 100, 100)
m2a <- lm(overall ~ rides + games + wait + clean + weekend,
data = sat.df)
summary(m2a)
contrasts(sat.df$weekend)
predict(m2a, data.frame(rides=c(100), games=c(100), wait=c(100), clean=c(100),
weekend=c("yes")))
coef(m2a)["(Intercept)"] + coef(m2a)["rides"]*100 + coef(m2a)["games"]*100 +
coef(m2)a["wait"]*100 + coef(m2a)["clean"]*100 + coef(m2a)["weekendyes"]*1
m2a <- lm(overall ~ rides + games + wait + clean + weekend,
data = sat.df)
summary(m2a)
contrasts(sat.df$weekend)
predict(m2a, data.frame(rides=c(100), games=c(100), wait=c(100), clean=c(100),
weekend=c("yes")))
coef(m2a)["(Intercept)"] + coef(m2a)["rides"]*100 + coef(m2a)["games"]*100 +
coef(m2)a["wait"]*100 + coef(m2a)["clean"]*100 + coef(m2a)["weekendyes"]*1
coef(m2a)["(Intercept)"] + coef(m2a)["rides"]*100 + coef(m2a)["games"]*100 +
coef(m2)a["wait"]*100 + coef(m2a)["clean"]*100 + coef(m2a)["weekendyes"]*1
contrasts(sat.df$weekend)
predict(m2a, data.frame(rides=c(100), games=c(100), wait=c(100), clean=c(100),
weekend=c("yes")))
coef(m2a)["(Intercept)"] + coef(m2a)["rides"]*100 + coef(m2a)["games"]*100 +
coef(m2)["wait"]*100 + coef(m2a)["clean"]*100 + coef(m2a)["weekendyes"]*1
contrasts(sat.df$weekend)
predict(m2a, data.frame(rides=c(100), games=c(100), wait=c(100), clean=c(100),
weekend=c("yes")))
coef(m2a)["(Intercept)"] + coef(m2a)["rides"]*100 + coef(m2a)["games"]*100 +
coef(m2a)["wait"]*100 + coef(m2a)["clean"]*100 + coef(m2a)["weekendyes"]*1
# Changing the coding scheme (note that the coding is a property of the factor)
contrasts(sat.df$weekend) <- contr.sum  # changes to sum contrasts (aka effect coding)
contrasts(sat.df$weekend)
m2b <- lm(overall ~ rides + games + wait + clean + weekend,
data = sat.df)
summary(m2b) # coeficients now match JMP
m3 <- lm(overall ~ rides + games + wait + clean + weekend + num.child,
data = sat.df)
summary(m3)
sat.df$num.child.factor <- factor(sat.df$num.child)
contrasts(sat.df$num.child.factor) # Default coding for a factor with 5 levels (R default)
contrasts(sat.df$num.child.factor) <- contr.sum
contrasts(sat.df$num.child.factor)
m4b <- lm(overall ~ rides + games + wait + clean + weekend + num.child.factor,
data=sat.df)
summary(m4b)
sat.df$has.child <- factor(sat.df$num.child > 0)
contrasts(sat.df$has.child) <- contr.sum
m5 <- lm(overall ~ rides + games + wait + clean + has.child,
data=sat.df)
summary(m5)
sat.df$has.child <- factor(sat.df$num.child > 0)
contrasts(sat.df$has.child) <- contr.sum
m5 <- lm(overall ~ rides + games + wait + clean + weekend + has.child,
data=sat.df)
summary(m5)
m6 <- lm(overall ~ rides + games + wait + clean + weekend + has.child +
rides:has.child + games:has.child + wait:has.child + clean:has.child +
rides:weekend + games:weekend + wait:weekend + clean:weekend,
data=sat.df)
summary(m6)
m6 <- lm(overall ~ rides + games + wait + clean + weekend + has.child +
wait:has.child,
data=sat.df)
summary(m6)
summary(sat.df$has.child)
summary(sat.df$has.child)
summary(sat.df$has.child.factor)
predict(m2a, data.frame(rides=c(100), games=c(100), wait=c(100), clean=c(100),
weekend=c("yes"), had.child=c(TRUE)))
predict(m2a, data.frame(rides=c(100), games=c(100), wait=c(100), clean=c(100),
weekend=c("yes"), had.child=c(TRUE)))
predict(m2a, data.frame(rides=c(100), games=c(100), wait=c(100), clean=c(100),
weekend=c("yes"), had.child=c(FALSE)))
predict(m2a, data.frame(rides=c(100), games=c(100), wait=c(100), clean=c(100),
weekend=c("no"), had.child=c(TRUE)))
summary(sat.df)
predict(m6, data.frame(rides=c(100), games=c(100), wait=c(100), clean=c(100),
weekend=c("yes"), had.child=c(TRUE)))
data.frame(rides=rep(100,4), games=rep(100,4), wait=rep(100,4), clean=rep(100,4))
data.frame(rides=rep(100,4), games=rep(100,4), wait=rep(100,4), clean=rep(100,4),
weekend=("yes", "yes", "no", "no"), has.child=c(TRUE, FALSE, TRUE, FALSE))
pred.df <- data.frame(rides=rep(100,4), games=rep(100,4), wait=rep(100,4),
clean=rep(100,4), weekend=("yes", "yes", "no", "no"),
has.child=c(TRUE, FALSE, TRUE, FALSE))
pred.df <- data.frame(rides=rep(100,4), games=rep(100,4), wait=rep(100,4),
clean=rep(100,4), weekend=c("yes", "yes", "no", "no"),
has.child=c(TRUE, FALSE, TRUE, FALSE))
pred.df
predict(m6, pred.df)
pred.df <- data.frame(rides=rep(100,4), games=rep(100,4), wait=rep(100,4),
clean=rep(100,4), weekend=c("yes", "yes", "no", "no"),
has.child=as.factor(c(TRUE, FALSE, TRUE, FALSE)))
predict(m6, pred.df)
pred.df
pred.df$prediction <- predict(m6, pred.df)
pred.df
pred.df$prediction <- predict(m6, pred.df)
pred.df
summary(m6)
pred.df <- data.frame(rides=rep(100,4), games=rep(100,4), clean=rep(100,4),
weekend=rep("yes",4), wait=c(50, 50, 80, 80),
has.child=as.factor(c(TRUE, FALSE, TRUE, FALSE)))
pred.df
pred.df$prediction <- predict(m6, pred.df)
pred.df
pred.df <- data.frame(rides=rep(100,4), games=rep(100,4), clean=rep(100,4),
weekend=rep("yes",4), wait=c(50, 80, 50, 80),
has.child=as.factor(c(FALSE, FALSE, TRUE, TRUE)))
pred.df
pred.df$prediction <- predict(m6, pred.df)
pred.df
rm(list=ls())
prop.test(x=c(.032,.038),n=(1000,1000),conf.level=.95)
prop.test(x=c(.032,.038),n=1000,conf.level=.95)
prop.test(x=c(.032,.038),n=1000,conf.level=.95)
prop.test(.032,1000,conf.level=.95)
power.t.test(n=156, delta=500, sd=1200,sig.level = .05, power=.95)
power.t.test (n=156, delta=500, sd=1200,sig.level = .05, power=.95)
power.t.test (n=176, delta=500, sd=1200, sig.level = 0.05, power=.95)
x <- c(2, 4, 6, 8)
x
X
# Vectors
# ==========
xNum  <- c(1, 3.14159, 5, 7)
xNum
xLog  <- c(TRUE, FALSE, TRUE, TRUE)
xLog
summary(XLog)
summary(xLog)
data(Iris)
data("iris")
View(iris)
summary(iris)
?power.prop.test
power.prop.test(p1=0.3, p=0.4, sig.level=0.05, power=0.95)
power.prop.test(p1=0.3, p2=0.4, sig.level=0.05, power=0.95)
power.prop.test(p1=0.3, p2=0.4, sig.level=0.20, power=0.95)
power.prop.test(p1=0.3, p2=0.4, sig.level=0.20, power=0.90)
power.prop.test(p1=0.3, p2=0.35, sig.level=0.20, power=0.90)
library(choiceDes)
install.packages(choiceDes)
install.packages('choiceDes')
library(choiceDes)
levs1 <- c(3,3,5,4)
des <- dcm.design(levs1, 10, 6, 2)
des
power.prop.test(p1=0.019, p2=0.024, sig.level=0.05, power=0.9, alternative="two.sided")
dnorm(1.64)
pnorm(1-.1)
qnorm(1-.1)
?pnorm
dnorm(1.64)
pnorm(0.1)
pnorm(1-.8)
pnorm(1-.9)
pnorm(1-.2/2)
pnorm(0.95)
pnorm(0.975)
qnorm(0.95)
qnorm(0.975)
qnorm(1-.2/2)
qnorm(1-0.1/2)
?power.t.test
power.prop.test(p1=0.001, p2=0.002, sig.level=0.05, power=0.95, alternative="two.sided")
power.prop.test(p1=0.001, p2=0.002, sig.level=0.10, power=0.90, alternative="two.sided")
power.prop.test(p1=0.001, p2=0.002, sig.level=0.10, power=0.80, alternative="two.sided")
power.prop.test(p1=0.001, p2=0.00125, sig.level=0.10, power=0.80, alternative="two.sided")
power.prop.test(p1=0.5, p2=0.6, sig.level=0.1, power=0.9)
?power.t.test
?glm
power.prop.test(p1=0.02, p2=0.03, power=0.9)
?prop.test
prop.test(x=c(0,6), n=c(13,97))
prop.test(x=c(3,0), n=c(8,6))
prop.test(x=c(3,0), n=c(8,6),conf.level=0.9)
prop.test(x=c(3,0), n=c(8,6),conf.level=0.8)
prop.test(x=c(3,0), n=c(9,7))
power.prop.test(p1=0.25, p2=0.255)
power.prop.test(p1=0.25, p2=0.255, power=0.3)
power.prop.test(p1=0.25, p2=0.255, power=0.3, sig.level=0.1)
18956*2
power.prop.test(p1=0.25, p2=0.255, power=0.3, sig.level=0.1, alternative="one.sided")
power.prop.test(p1=0.25, p2=0.27, power=0.3, sig.level=0.1)
prop.test(x=c(244,206), n=c(529,518))
?t.test
?power.t.test
power.t.test(delta=1, sd=3, sig.level=0.05, power=.9)
power.t.test(delta=1, sd=3, sig.level=0.05, power=.9, alternative="one.sided")
77*2
154*2/16
prop.test(x=c(142,40), n=c(162975,49341))
power.prop.test(p1=0.05, p2=0.06, power=0.80, sig.level=0.84)
power.prop.test(p1=0.05, p2=0.06, power=0.20, sig.level=0.84)
power.prop.test(p1=0.05, p2=0.06, power=0.50, sig.level=0.84)
power.prop.test(p1=0.05, p2=0.06, power=0.70, sig.level=0.84)
power.prop.test(p1=0.05, p2=0.06, power=0.60, sig.level=0.84)
power.prop.test(p1=0.05, p2=0.06, power=0.65, sig.level=0.84)
power.prop.test(p1=0.05, p2=0.06, power=0.70, sig.level=0.84)
power.prop.test(p1=0.5, p2=0.70, power=0.80, sig.level=0.10)
power.prop.test(p1=0.56, p2=0.40, power=0.80, sig.level=0.10)
power.prop.test(p1=0.34, p2=0.40, power=0.80, sig.level=0.10)
power.prop.test(p1=0.40, p2=0.56, power=0.80, sig.level=0.10)
power.prop.test(p1=0.40, p2=0.56, power=0.80, sig.level=0.10, type="one.sided")
power.prop.test(p1=0.40, p2=0.56, power=0.80, sig.level=0.10, alternative = ="one.sided")
power.prop.test(p1=0.40, p2=0.56, power=0.80, sig.level=0.10, alternative = "one.sided")
power.prop.test(p1=0.24, p2=0.40, power=0.80, sig.level=0.10, alternative = "one.sided")
power.prop.test(p1=0.32, p2=0.48, power=0.80, sig.level=0.10, alternative = "one.sided")
?"likelihood ratio test"
?anova
?lrtest
??lrtest
?chisq.dist
??"chi-squared"
(-6767+6691)
2*(-6767+6691)
2*(-6691+6767)
pchisq(152,df=10)
pchisq(152,df=10, lower.tail=FALSE)
pchisq(2*(-4592+4524),df=10, lower.tail=FALSE)
2*(-4592+4524)
2*(-4524+4592)
pchisq(2*(-4592+4524), df=10, lower.tail = FALSE)
pchisq(2*(-4592+4524), df=10, lower.tail = TRUE)
qchisq(2*(-4592+4524), df=10, lower.tail = TRUE)
qchisq(2*(-4592+4524), df=10)
2*(-4524+4592)
qchisq(2*(-4524+4592), df=10)
pchisq(24, df=2)
pchisq(24, df=2, lower.tail=TRUE)
pchisq(24, df=2, lower.tail=FALSE)
pchisq(2*(92-24), df=10, lower.tail=FALSE)
pchisq(2*(4592-4524), df=10, lower.tail=FALSE)
pchisq(152, df=10, lower.tail=FALSE)
pchisq(2*(-6691-(-6767)), df=10, lower.tail=FALSE)
?sample
install.packages("readxl")
library("readxl")
?read_excel
upc <- read_excel("/Volumes/ADS_235/Academic Dataset External/parsed stub files 2008-2011/prod11_factiss.xlsx")
head(upc)
summary(upc)
head(panel)
library(data.table)
store <- fread("/Volumes/ADS_235/Academic Dataset External/Year6/External/factiss/factiss_groc_1374_1426")
panel <- fread("/Volumes/ADS_235/Academic Dataset External/Year6/External/factiss/factiss_PANEL_GR_1374_1426.DAT")
library("readxl")
upc <- read_excel("/Volumes/ADS_235/Academic Dataset External/parsed stub files 2008-2011/prod11_factiss.xlsx")
summary(upc)
head(upc)
head(store)
store[store$WEEK==1388 & store$IRI_KEY==272568,]
head(upc)
upc[upc$UPC=="00-01-42887-40492",]
head(panel)
panel$COLUPC <- as.character(panel$COLUPC)
panel$COLUPC <- as.character(panel$COLUPC)
head(panel)
panel <- fread("/Volumes/ADS_235/Academic Dataset External/Year6/External/factiss/factiss_PANEL_GR_1374_1426.DAT")
?fread
panel <- fread("/Volumes/ADS_235/Academic Dataset External/Year6/External/factiss/factiss_PANEL_GR_1374_1426.DAT",
colClasses=c(COLUPC="character"))
head(panel)
summary(panel)
panel[panel$IRI_KEY==272568,]
head(panel)
panel[1,]
purch <- panel[1,]
purch$PANID
store[store$WEEK==panel$WEEK & store$IRI_KEY==panel$IRI_KEY,]
r <- 1
panel[r,]
store[store$WEEK==panel[r,]$WEEK & store$IRI_KEY==panel[r,]$IRI_KEY,]
panel[r,\]
panel[r,]
upc[upc$UPC=="00-01-36000-24200",]
upc[upc$UPC=="00-01-36000-24200",] # Kleenex, top opening, plastic wrapped box"
# all sales in that week at that store
store[store$WEEK==panel[r,]$WEEK & store$IRI_KEY==panel[r,]$IRI_KEY,]
panel[r,]$DOLLARS/panel[r,]$UNITS
panel[r,]
head(panel)
summary(panel)
head(upc)
head(store)
upc.carb <- read_excel("/Volumes/ADS_235/Academic Dataset External/parsed stub files 2008-2011/prod11_carbbev.xlsx")
head(upc.carb)
r <- 1
panel[r,]
upc[upc$UPC=="00-01-36000-24200",] # Kleenex, top opening, plastic wrapped box"
store[store$WEEK==panel[r,]$WEEK & store$IRI_KEY==panel[r,]$IRI_KEY,]
dim(store)
dim(panel)
library(data.table)
store <- fread("/Volumes/ADS_235/Academic Dataset External/Year6/External/factiss/factiss_groc_1374_1426")
store[store$WEEK==panel[r,]$WEEK & store$IRI_KEY==panel[r,]$IRI_KEY,]
head(store)
head(upc)
summary(as.factor(upc$L5))
str(upc)
head(panel)
summary(store$F)
summary(as.factor(store$F))
summary(as.factor(store$D))
summary(as.factor(store$PR))
head(panel)
install.packages("installR")
rm(list=ls())
# ===== Is My Advertising Working?=====
# Elea McDonnell Feit
# efeit@wharton.upenn.edu
# Last updated 8 May 2017, Version 1.0
# This file is a companion to the workshop on "Is my advertising working?"
# first offered in conjunction with the Wharton Customer Analytics Initiative
# annual conference.
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
#
# You may obtain a copy of the License at
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
rm(list=ls()) # clears the workspace
set.seed("20030603") #ensures repeatable results for attribution rules
setwd("~/Google Drive/_Workshops/2017 Ad response tutorial/R code") # set your working directory
options(scipen=999) # supress scientific notation
# ====== Read in data and explore ========
# == Customer table ==
cust <- read.csv("https://goo.gl/mqy8NR")
nrow(cust)
summary(cust)
xtabs(~email+direct+past.purchase, data=cust)
# == Impressions table ==
impress <- read.csv("https://goo.gl/74qIxy")
impress$date <- as.Date(impress$date) # change type
nrow(impress)
summary(impress)
# Cadence
(cadence <- xtabs(~date+channel, data=impress))
# Visualize the cadence
cadence <- cadence[,c(2,5,1,3,4)] # reorder the columns
mycols <- c("gray50", "wheat2", "darkorange2", "steelblue2", "steelblue4")
barplot(t(cadence), col=mycols, ylab="impressions")
legend("topright", legend=colnames(cadence), fill=mycols, cex=0.6)
# Impressions per person
hist(xtabs(~id, data=impress), xlab="Impressions", ylab="Count of Users",
main="Histogram of Impressions per User")
# Click through rates by channel
xtabs(click~channel, data=impress)/xtabs(~channel, data=impress)
# ==Transactions table==
trans <- read.csv("https://goo.gl/lIAuZu")
trans$date <- as.Date(trans$date)
summary(trans)
# Transactions over time
(transbyday <- xtabs(~date, data=trans))
# Plot of transactions over time
plot(transbyday, ylab="Transactions", xlab="Date")
# Transactions per person
hist(xtabs(~id, data=trans), xlab="Number of Transactions", ylab="Count of Users",
main="Histogram of Transactions")
# Timeline for one customer
cust[cust$id==100,]
impress[impress$id==100,]
trans[trans$id==100,]
cust[cust$id==300,]
summary(impress[impress$id==300,])
trans[trans$id==300,]
# ====== Last-Click Attribution =======
(last.touch.att <- xtabs(~last.touch, data=trans))
barplot(last.touch.att, ylab="Transactions",
main="Last Touch Attribution")
# For the month of February
xtabs(~last.touch, data=trans[trans$date>as.Date("2017-01-31"),])
